{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f929f400-503b-4f84-b3c6-a3507fe0ea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv( r\"C:\\Users\\Akash Giri\\Documents\\PyWork\\PGDM_GenAI\\myAPI.env\"))\n",
    "\n",
    "# openai_api_key  = os.getenv('OPENAI_KEY_PGDM') #('OPENAI_API_KEY')\n",
    "# openai.api_key = openai_api_key\n",
    "\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(\n",
    "#     api_key = os.environ[\"GEMINI_API_KEY\"], \n",
    "#     base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d79d05c-e89d-4095-8499-7f60d85aaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "basic_model = init_chat_model(\n",
    "    model = \"gemini-2.0-flash\",  #\"claude-sonnet-4-5-20250929\",\n",
    "    api_key = os.environ[\"GEMINI_API_KEY\"], \n",
    "    model_provider = \"google_genai\",\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "advanced_model = init_chat_model(\n",
    "    model = \"gemini-2.5-flash\",  #\"claude-sonnet-4-5-20250929\",\n",
    "    api_key = os.environ[\"GEMINI_API_KEY\"], \n",
    "    model_provider = \"google_genai\",\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "# basic_model = client.chat.completions.create(\n",
    "#     model = \"gemini-2.0-flash\", \n",
    "#     messages = [{\"role\": \"user\", \"content\": \"Act as an assistant\"}],  \n",
    "#     # max_tokens = \n",
    "#     # temperature = \n",
    "#     # max_p =\n",
    "#     # max_k =\n",
    "# )\n",
    "\n",
    "# advaced_model = client.chat.completions.create(\n",
    "#     model = \"gemini-2.0-flash\", \n",
    "#     messages = [{\"role\": \"user\", \"content\": \"Act as an assistant\"}],  \n",
    "#     # max_tokens = \n",
    "#     # temperature = \n",
    "#     # max_p =\n",
    "#     # max_k =\n",
    "# )\n",
    "\n",
    "# basic_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# advanced_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def get_weather(city: str) -> str:  \n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "# \n",
    "tools=[get_weather]\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 10:\n",
    "        # Use an advanced model for longer conversations\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    request.model = model\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,  # Default model\n",
    "    tools=tools,\n",
    "    middleware=[dynamic_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93308a3b-269e-47e0-ae93-a35a48cc1e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather at Delhi?', additional_kwargs={}, response_metadata={}, id='9e4f98a7-a84e-4ed2-bc2f-d194e7d41b80'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Delhi\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--fef9b726-441b-4727-98d6-adc7c91291e8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Delhi'}, 'id': 'eb865b43-8947-48c3-bb35-67a74357f662', 'type': 'tool_call'}], usage_metadata={'input_tokens': 21, 'output_tokens': 5, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in Delhi!\", name='get_weather', id='7830bdac-079a-48ff-a76c-9b431fbb6546', tool_call_id='eb865b43-8947-48c3-bb35-67a74357f662'),\n",
       "  AIMessage(content=\"It's always sunny in Delhi!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--6235daf4-ceb3-4bc2-ae75-e152f6308f70-0', usage_metadata={'input_tokens': 38, 'output_tokens': 9, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather at Delhi?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22daf5c4-a5c3-4b24-b462-ab9fc1e74e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather at Mumbai?', additional_kwargs={}, response_metadata={}, id='40010445-077c-4f52-800c-154462e4c32f'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Mumbai\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--2f4e5cbc-a03c-49dd-b68a-d729b8078e4c-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Mumbai'}, 'id': 'a2dc9a42-7580-4b7e-83bb-43e90e1e0a93', 'type': 'tool_call'}], usage_metadata={'input_tokens': 21, 'output_tokens': 5, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in Mumbai!\", name='get_weather', id='76f75dc6-3a79-411b-b445-3e2ad15df0f1', tool_call_id='a2dc9a42-7580-4b7e-83bb-43e90e1e0a93'),\n",
       "  AIMessage(content=\"It's always sunny in Mumbai!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--c41bac0f-571b-4be7-a726-e6a4dcd257c0-0', usage_metadata={'input_tokens': 38, 'output_tokens': 9, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather at Mumbai?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d403ece-e56c-42cc-8fb2-fc8ef4e25726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Pregel.stream at 0x0000021C589F06D0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.stream({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather at Delhi?\"}]}, \n",
    "            stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf358d54-d975-440f-a8f5-8077c8b2d744",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CompiledStateGraph' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agent:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[0;32m      3\u001b[0m         event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'CompiledStateGraph' object is not iterable"
     ]
    }
   ],
   "source": [
    "for event in agent:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe90db5-a35d-4257-a66e-0e6faa7a7d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
