{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a1bf8a-c4ab-4162-93f5-e54fb275ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7ce039-86f8-4c44-8af7-fbbf3f78c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee29d6ff-05de-438c-af95-52801e9a3f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os #, openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv( r\"C:\\Users\\Dr. Bhavesh Dharmani\\Documents\\PyWork\\PGDM_GenAI\\myAPI.env\"))\n",
    "\n",
    "# openai_api_key  = os.getenv('OPENAI_KEY_PGDM') #('OPENAI_API_KEY')\n",
    "# openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea03af7-7596-413c-9ed4-36321e00904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dr. Bhavesh Dharmani\\AppData\\Local\\Temp\\ipykernel_27496\\408453385.py:20: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in Delhi', additional_kwargs={}, response_metadata={}, id='822b3747-4181-4b0b-915a-b0f7331c0e50'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Delhi\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--428c9602-1d8f-4c23-9264-2cffd5dd8b4f-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Delhi'}, 'id': '87d6b9b9-33cf-4694-a203-40eb44ef39eb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 25, 'output_tokens': 5, 'total_tokens': 30, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"It's always sunny in Delhi!\", name='get_weather', id='56c5e2b5-0e3b-4d79-8878-aef7c7aec1da', tool_call_id='87d6b9b9-33cf-4694-a203-40eb44ef39eb'), AIMessage(content=\"It's always sunny in Delhi!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--1c1645f1-29d8-4a90-b2d2-90ba4cb2c480-0', usage_metadata={'input_tokens': 42, 'output_tokens': 9, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "# from langchain.agents import create_agent\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "# llm = init_chat_model(\"openai:gpt-4o\", api_key = openai_api_key)\n",
    "llm = init_chat_model(\n",
    "    model = \"gemini-2.0-flash\", \n",
    "    api_key = os.environ[\"GEMINI_API_KEY\"], \n",
    "    model_provider = \"google_genai\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:  \n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "# Agents could be directly created using create_agent() or create_react_agent() \n",
    "agent = create_react_agent(\n",
    "    model=llm,   #\"openai:gpt-4o\",  # \"anthropic:claude-3-7-sonnet-latest\",  \n",
    "    tools=[get_weather],  \n",
    "    prompt=\"You are a helpful assistant\")\n",
    "\n",
    "# agent = create_agent(\n",
    "#     model=llm,   #\"openai:gpt-4o\",  # \"anthropic:claude-3-7-sonnet-latest\",  \n",
    "#     tools=[get_weather],  \n",
    "#     system_prompt=\"You are a helpful assistant\")\n",
    "\n",
    "# Run the agent\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in Delhi\"}]}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bdffd3-43af-46fe-8d56-610e1d97eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's always sunny in Delhi!\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][3].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197d5fcc-76dd-407b-a567-050c2ad25ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in sf.', additional_kwargs={}, response_metadata={}, id='d6e2b748-fd16-4ef6-8d5f-42596115c9c9'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"sf\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--fdd0aa2b-b779-43d8-8b4a-119f80078ccd-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'd3914c2c-3729-4700-af60-99073aefda33', 'type': 'tool_call'}], usage_metadata={'input_tokens': 26, 'output_tokens': 5, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}}), ToolMessage(content=\"It's always sunny in sf!\", name='get_weather', id='900b9e84-fc74-426f-8966-2947f46b3558', tool_call_id='d3914c2c-3729-4700-af60-99073aefda33'), AIMessage(content=\"It's always sunny in sf!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='lc_run--f65f6001-d120-456d-aa05-9636b5ab54ef-0', usage_metadata={'input_tokens': 43, 'output_tokens': 9, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# from langgraph.prebuilt import create_react_agent\n",
    "# Compare to create_react_agent(), create_agent() is used to have a simple flow-graphs, \n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent2 = create_agent(\n",
    "    model=llm,   #\"openai:gpt-4o\",  # \"anthropic:claude-3-7-sonnet-latest\",  \n",
    "    tools=[get_weather],  \n",
    "    system_prompt=\"You are a helpful assistant\")\n",
    "\n",
    "# Run the agent\n",
    "response = agent2.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf.\"}]}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97519a5e-e5e0-4a8f-95ce-90bb07ae0378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's always sunny in sf!\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][3].content)\n",
    "# print(response[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c864a9-3f42-4aab-bdfc-a2feda8d77ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4157816-4852-4b81-a5e2-7e7210816f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfa085-9177-41a2-a9c2-c04cf28efe9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346c91f-b558-4390-b08b-e4c2485879a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
