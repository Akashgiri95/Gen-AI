{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f06ee64-9cf1-4aa1-b32a-53581247e314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (0.35.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e094eb54-ccfa-4b22-850a-9a741e38833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d77f391-e594-4c66-a2f2-8a00c31a8323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sentiment_analysis = pipeline(\n",
    "#     'sentiment-analysis', \n",
    "#      model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "#     revision=\"714eb0f\"   # optional but ensures reproducibility\n",
    "# )\n",
    "\n",
    "# test_examples = [\n",
    "#     {\"text\": \"I love this product!\", \"label\": 1}, \n",
    "#     {\"text\": \"The service was terrible.\", \"label\": 0}, \n",
    "#     {\"text\": \"This movie is amazing.\", \"label\": 1}, \n",
    "#     {\"text\": \"I'm disappointed with the quality.\", \"label\": 0}\n",
    "# ]\n",
    "\n",
    "# predictions = sentiment_analysis(\n",
    "#     [example[\"text\"] for example in test_examples] \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5860e83a-c07a-42a9-a64d-802525b2790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada294d0-53cc-4c5e-8ea9-967da8550577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:\n",
      "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
      " Where:\n",
      "TP: True positive\n",
      "TN: True negative\n",
      "FP: False positive\n",
      "FN: False negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "print(accuracy.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57df5f5a-7cad-4bd6-930e-ef8004409c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The F1 score is the harmonic mean of the precision and recall. It can be computed with the equation:\n",
      "F1 = 2 * (precision * recall) / (precision + recall)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate.load(\"f1\").description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6b7f32-746f-48af-bf8f-9a4590bb226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': Value('int32'), 'references': Value('int32')}\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c034a4-14b7-413d-bc59-dca54b638ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': Value('int32'), 'references': Value('int32')}\n"
     ]
    }
   ],
   "source": [
    "f1 = evaluate.load(\"f1\")\n",
    "print(f1.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20122dc1-cc94-430c-8cca-bb2b0295c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': Value('float32'), 'references': Value('float32')}\n"
     ]
    }
   ],
   "source": [
    "pearson_scorr = evaluate.load(\"pearsonr\")\n",
    "print(pearson_scorr.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19048d59-fa01-4739-9ed5-cefca7584adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4239e427-6c0f-4319-ad4c-d496f8e32cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import torch\n",
    "\n",
    "# 1. Load tokenizer & model\n",
    "# ---------------------------\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# GPT-2 does not have a padding token â†’ set pad token to eos token to avoid warnings\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c68dfcc-08bf-45ba-a8a1-bba16e78f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest research findings in Antarctica show that the ice sheet is melting faster than previously thought.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"gpt2\"\n",
    "\n",
    "prompt = \"Latest research findings in Antarctica show\"\n",
    "\n",
    "prompt_ids = tokenizer.encode(prompt, return_tensors = 'pt')  # test_sentence\n",
    "output = model.generate(prompt_ids, max_length = 17)\n",
    "generated_text = tokenizer.decode(\n",
    "    output[0], skip_special_tokens = True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32424f4e-aabc-41bf-a2bf-66c17920774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c5ca42491e42e986ecbfab8721795e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867.6824600219725\n"
     ]
    }
   ],
   "source": [
    "perplexity = evaluate.load('perplexity', module_type = \"metric\")\n",
    "results = perplexity.compute(model_id = 'gpt2', predictions = generated_text)\n",
    "print(results['mean_perplexity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e9cd42-5180-437d-8d02-b8c0846b3601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': Value('string')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530492d1-2b70-433b-b87f-716344bbd861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: absl-py in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from rouge_score) (2.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\dr. bhavesh dharmani\\anaconda3\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=3e940bf59c90559b6460da427eaf05552c733b27aaaa9389e7bf5300194c1922\n",
      "  Stored in directory: c:\\users\\dr. bhavesh dharmani\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97578b8-0230-436d-a2db-f838abf75d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.7906976744186046, 'rouge2': 0.5365853658536585, 'rougeL': 0.7441860465116279, 'rougeLsum': 0.7441860465116279}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "predictions = [\"\"\"As we learn more about the frequency and size distribution of exoplanets, we are dicovering \n",
    "    that terrestrial planets are exceedingly common.\"\"\"]\n",
    "\n",
    "references = [\"\"\"The more we learn about the frequency and size distribution of exoplanets, the more\n",
    "confident we are that they are exceedingly common.\"\"\"]\n",
    "results = rouge.compute(predictions = predictions, references = references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cf8136-7f8f-423f-a6b0-eac5cbe2df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7906976744186046\n"
     ]
    }
   ],
   "source": [
    "print(results[\"rouge1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b7d186-063a-4f88-8c34-c158636f49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.7906976744186046, 'rouge2': 0.5365853658536585, 'rougeL': 0.7441860465116279, 'rougeLsum': 0.7441860465116279}\n"
     ]
    }
   ],
   "source": [
    "rouge2 = evaluate.load(\"rouge\")\n",
    "results1 = rouge.compute(predictions = predictions, references = references)\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a384628f-1aa7-4843-bbb9-0e568fdd4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated candidate: {'rouge1': 0.3636363636363636, 'rouge2': 0.0, 'rougeL': 0.3636363636363636, 'rougeLsum': 0.3636363636363636}\n",
      "Correct candidate: {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Rouge clipping implmentation \n",
    "\n",
    "# import evaluate\n",
    "# rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Reference summary\n",
    "reference = [\"The cat sat on the mat\"]\n",
    "\n",
    "# Candidate with repetition (trying to game ROUGE)\n",
    "predictions = [\"The the the the the\"]\n",
    "\n",
    "# Candidate with correct wording\n",
    "candidate_correct = [\"The cat sat on the mat\"]\n",
    "\n",
    "# Compute ROUGE\n",
    "results_repeated = rouge.compute(predictions=predictions, references=reference)\n",
    "results_correct = rouge.compute(predictions=candidate_correct, references=reference)\n",
    "\n",
    "print(\"Repeated candidate:\", results_repeated)\n",
    "print(\"Correct candidate:\", results_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d45258c-29b8-4901-84c0-c7a9c700ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'predictions': Value('string'), 'references': List(Value('string'))}, {'predictions': Value('string'), 'references': Value('string')}]\n"
     ]
    }
   ],
   "source": [
    "print(rouge.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7350d52-2dde-4a97-b120-ea406ee0f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.5387958246253988, 'precisions': [1.0, 0.8333333333333334, 0.6363636363636364, 0.4], 'brevity_penalty': 0.7939226578179512, 'length_ratio': 0.8125, 'translation_length': 13, 'reference_length': 16}\n",
      "{'bleu': 0.7497153770440844, 'precisions': [1.0, 0.9230769230769231, 0.8333333333333334, 0.7272727272727273], 'brevity_penalty': 0.8668778997501817, 'length_ratio': 0.875, 'translation_length': 14, 'reference_length': 16}\n",
      "{'bleu': 0.8196501312471536, 'precisions': [1.0, 0.9285714285714286, 0.8461538461538461, 0.75], 'brevity_penalty': 0.9355069850316178, 'length_ratio': 0.9375, 'translation_length': 15, 'reference_length': 16}\n",
      "{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 16, 'reference_length': 16}\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "references = [\"I am very happy to say that I am drinking a warm cup of tea.\"]\n",
    "\n",
    "predictions_1 = [\"I am very happy that I am drinking a cup of tea.\"]\n",
    "predictions_2 = [\"I am very happy that I am drinking a warm cup of tea.\"]\n",
    "predictions_3 = [\"I am very happy to say that I am drinking a cup of tea.\"] \n",
    "predictions_4 = [\"I am very happy to say that I am drinking a warm cup of tea.\"]\n",
    "\n",
    "results_1 = bleu.compute(predictions = predictions_1, references = references)\n",
    "results_2 = bleu.compute(predictions = predictions_2, references = references)\n",
    "results_3 = bleu.compute(predictions = predictions_3, references = references)\n",
    "results_4 = bleu.compute(predictions = predictions_4, references = references)\n",
    "print(results_1)\n",
    "print(results_2)\n",
    "print(results_3)\n",
    "print(results_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6af558b-f795-4bbf-b96d-d7509cf5b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Dr. Bhavesh\n",
      "[nltk_data]     Dharmani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Dr. Bhavesh\n",
      "[nltk_data]     Dharmani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Dr. Bhavesh\n",
      "[nltk_data]     Dharmani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu:  {'bleu': 0.27434490219813984, 'precisions': [0.6451612903225806, 0.3, 0.2413793103448276, 0.17857142857142858], 'brevity_penalty': 0.9077609612738833, 'length_ratio': 0.9117647058823529, 'translation_length': 31, 'reference_length': 34}\n",
      "Meteor:  {'meteor': 0.5095984981529704}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "\n",
    "preds = [\"\"\"He thought it right and necessary to become a knight-errant, travelling the \n",
    "world in armor, \n",
    "seekng adventures and practicing the deeds he had read about in chivalric tales.\"\"\"]\n",
    "\n",
    "refs = [\"\"\" He believed it was proper and essential to transform into knight-errant, \n",
    "travelling the world in armor, persuing adventures, amd enacting the heeroic deeds he\n",
    "had encountered in tales of chivalry.\"\"\"]\n",
    "\n",
    "results_b = bleu.compute(predictions = preds, references = refs)\n",
    "results_m = meteor.compute(predictions = preds, references = refs)\n",
    "print(\"Bleu: \", results_b)\n",
    "print(\"Meteor: \", results_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa036f7d-afc7-4634-8f9d-9d40a72be730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "import evaluate \n",
    "\n",
    "em = evaluate.load(\"exact_match\")\n",
    "predictions = [\"The cat sat on the mat.\", \n",
    "            \"Theaters are great.\", \n",
    "            \"It's like comparing oranges and apples.\"]\n",
    "references = [\"The cat sat on the mat?\", \n",
    "             \"Theaters are great.\", \n",
    "             \"It's like comparing apples and oranges.\"]\n",
    "results_em = em.compute(predictions = predictions, references = references)\n",
    "print(results_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e7cbb3-dd13-4afb-9ef6-eecd235e6851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity in Pred_1 is:  {'toxicity': [0.0001413044665241614, 0.00013581576058641076]}\n",
      "Toxicity in Pred_2 is:  {'toxicity': [0.00014405461843125522, 0.0057794381864368916]}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "toxicity = evaluate.load(\"toxicity\")\n",
    "\n",
    "pred_1 = [\"Everyone in the team adores him.\",\n",
    "         \"He is a true genius, pure talent.\"]\n",
    "pred_2 = [\"Nobody in the team likes him.\", \n",
    "         \"He is a useless 'good-for-nothing'. \"]\n",
    "\n",
    "toxicity_res1 = toxicity.compute(predictions = pred_1)\n",
    "print(\"Toxicity in Pred_1 is: \", toxicity_res1)\n",
    "toxicity_res1 = toxicity.compute(predictions = pred_2)\n",
    "print(\"Toxicity in Pred_2 is: \", toxicity_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf857f5-2f4d-4ad4-9f62-14f07436c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity in Pred_1 is:  {'max_toxicity': 0.0001413044665241614}\n",
      "Toxicity in Pred_2 is:  {'max_toxicity': 0.0057794381864368916}\n"
     ]
    }
   ],
   "source": [
    "toxicity_res1 = toxicity.compute(predictions = pred_1, aggregation = \"maximum\")\n",
    "print(\"Toxicity in Pred_1 is: \", toxicity_res1)\n",
    "toxicity_res1 = toxicity.compute(predictions = pred_2, aggregation = \"maximum\")\n",
    "print(\"Toxicity in Pred_2 is: \", toxicity_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b0b0ba-f5d3-4cec-9218-6798ddc47a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity in Pred_1 is:  {'toxicity_ratio': 0.0}\n",
      "Toxicity in Pred_2 is:  {'toxicity_ratio': 0.0}\n"
     ]
    }
   ],
   "source": [
    "toxicity_res1 = toxicity.compute(predictions = pred_1, aggregation = \"ratio\")\n",
    "print(\"Toxicity in Pred_1 is: \", toxicity_res1)\n",
    "toxicity_res1 = toxicity.compute(predictions = pred_2, aggregation = \"ratio\")\n",
    "print(\"Toxicity in Pred_2 is: \", toxicity_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9271122f-da1c-4ae5-968f-5c5b97567812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_1:  {'regard': [[{'label': 'positive', 'score': 0.8298447728157043}, {'label': 'other', 'score': 0.0996326208114624}, {'label': 'neutral', 'score': 0.05163787677884102}, {'label': 'negative', 'score': 0.018884729593992233}], [{'label': 'positive', 'score': 0.3437841236591339}, {'label': 'neutral', 'score': 0.3377510905265808}, {'label': 'other', 'score': 0.18729078769683838}, {'label': 'negative', 'score': 0.13117395341396332}]]}\n",
      "eval_2:  {'regard': [[{'label': 'negative', 'score': 0.9624267816543579}, {'label': 'other', 'score': 0.023236598819494247}, {'label': 'neutral', 'score': 0.013599522411823273}, {'label': 'positive', 'score': 0.0007369781378656626}], [{'label': 'negative', 'score': 0.9755293130874634}, {'label': 'other', 'score': 0.014527562074363232}, {'label': 'neutral', 'score': 0.009333696216344833}, {'label': 'positive', 'score': 0.0006093884003348649}]]}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "regard = evaluate.load(\"regard\")\n",
    "\n",
    "pred_1 = [\"abc are described as loyal employees.\", \n",
    "         \"abc are ambitious in their career expectations.\"]\n",
    "pred_2 = [\"abc are known for causing lots of team conflicts.\", \n",
    "         \"abc are verbally violent.\"]\n",
    "\n",
    "eval_1 = regard.compute(data = pred_1)\n",
    "eval_2 = regard.compute(data = pred_2)\n",
    "print(\"eval_1: \", eval_1)\n",
    "print(\"eval_2: \", eval_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece1a9d-c086-4033-984f-d16948bea9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
