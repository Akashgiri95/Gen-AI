{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f41003",
   "metadata": {},
   "source": [
    "# Lab 3: Mastering Prompt Engineering with Gemini 2.0 Flash\n",
    "\n",
    "**Course:** Introduction to Generative AI and Prompt Engineering\n",
    "\n",
    "**Duration:** 2 hours\n",
    "\n",
    "This notebook contains hands-on exercises covering zero-shot, few-shot, role prompting, chain-of-thought, JSON extraction, multi-modal prompting, and self-consistency techniques tailored for `gemini-2.0-flash`.\n",
    "\n",
    "Each exercise has: 1) prompt template, 2) sample input, 3) expected output (where applicable), and 4) a code cell that students can adapt to call the Gemini API in their environment.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2b60d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Google Colab or local Jupyter with access to Gemini API (or equivalent environment).\n",
    "- `gemini-2.0-flash` model credentials / API key configured.\n",
    "\n",
    "If you're using the Google Gemini Python SDK or OpenAI-like wrapper, replace the placeholder call in the example cells with the provider-specific client code.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd30478f-bc67-47f2-8c6a-c0b26db361b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv( r\"C:\\Users\\Dr. Bhavesh Dharmani\\Documents\\PyWork\\PGDM_GenAI\\myAPI.env\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9748fb7d-8a9c-4a2e-9739-b0c9eec5a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# from google import genai\n",
    "# gemini_client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139b965",
   "metadata": {},
   "source": [
    "## Phase 1 — Explore (30 min)\n",
    "\n",
    "### 1. Zero-shot Prompting\n",
    "\n",
    "**Task:** Summarize a business text in 3 bullet points focusing on sales performance.\n",
    "\n",
    "**Sample text:**\n",
    "\n",
    "\"Our quarterly sales grew by 15% in North America, driven by online campaigns. However, Asia-Pacific saw a decline due to supply chain disruptions. The new product line 'EcoSmart' contributed 25% of total sales.\"\n",
    "\n",
    "### Prompt template (Zero-shot):\n",
    "\n",
    "```\n",
    "Summarize the following business report in 3 bullet points focusing on sales performance:\n",
    "\n",
    "[TEXT HERE]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c19885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a 3-bullet point summary of the sales performance:\n",
      "\n",
      "*   **Strong Growth in North America:** Quarterly sales increased by 15% in North America, fueled by successful online marketing initiatives.\n",
      "*   **Asia-Pacific Decline:** Sales in the Asia-Pacific region decreased due to ongoing supply chain challenges.\n",
      "*   **EcoSmart Success:** The new 'EcoSmart' product line significantly contributed to overall revenue, accounting for 25% of total sales.\n"
     ]
    }
   ],
   "source": [
    "# Example: prepare prompt string\n",
    "\n",
    "text = (\n",
    "    \"Our quarterly sales grew by 15% in North America, driven by online campaigns. \"\n",
    "    \"However, Asia-Pacific saw a decline due to supply chain disruptions. \"\n",
    "    \"The new product line 'EcoSmart' contributed 25% of total sales.\"\n",
    ")\n",
    "\n",
    "prompt = f\"Summarize the following business report in 3 bullet points focusing on sales performance:\\n\\n{text}\"\n",
    "# print(prompt)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gemini-2.0-flash\",    #\"gemini-1.5-flash\", \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}], \n",
    "    max_tokens = 100\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# ---\n",
    "# Replace the following pseudo-call with actual Gemini API call in your environment.\n",
    "# Example placeholder (DO NOT run unless you have an API client configured):\n",
    "# response = gemini_client.complete(model='gemini-2.0-flash', prompt=prompt)\n",
    "# print(response.text)\n",
    "\n",
    "# Sample expected output (for instructors):\n",
    "# expected = \"- North America sales increased 15%, driven by online campaigns.\\n- Asia-Pacific sales declined due to supply chain disruptions.\\n- 'EcoSmart' product line contributed 25% of total sales.\"\n",
    "# print('\\nExpected output:\\n', expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef5178",
   "metadata": {},
   "source": [
    "### 2. Few-shot Prompting\n",
    "\n",
    "Provide examples so the model follows the structure for extracting product names and contribution percent.\n",
    "\n",
    "Example prompt (few-shot):\n",
    "\n",
    "```\n",
    "Extract the product name and its contribution from the following texts.\n",
    "\n",
    "Example 1:\n",
    "Text: \"The AI-powered SmartDesk accounted for 30% of sales.\"\n",
    "Output: {\"product_name\": \"SmartDesk\", \"sales_contribution\": \"30%\"}\n",
    "\n",
    "Example 2:\n",
    "Text: \"EcoSmart line contributed 25% of total sales.\"\n",
    "Output: {\"product_name\": \"EcoSmart\", \"sales_contribution\": \"25%\"}\n",
    "\n",
    "Now extract from:\n",
    "\"The UltraCharge battery series achieved 40% of the market share.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6dbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot prompt creation\n",
    "examples = '''Extract the product name and its contribution from the following texts.\n",
    "\n",
    "Example 1:\n",
    "Text: \"The AI-powered SmartDesk accounted for 30% of sales.\"\n",
    "Output: {\"product_name\": \"SmartDesk\", \"sales_contribution\": \"30%\"}\n",
    "\n",
    "Example 2:\n",
    "Text: \"EcoSmart line contributed 25% of total sales.\"\n",
    "Output: {\"product_name\": \"EcoSmart\", \"sales_contribution\": \"25%\"}\n",
    "\n",
    "Now extract from:\n",
    "\"The UltraCharge battery series achieved 40% of the market share.\"'''\n",
    "\n",
    "print(examples)\n",
    "\n",
    "# Placeholder for API call\n",
    "# response = gemini_client.complete(model='gemini-2.0-flash', prompt=examples)\n",
    "# print(response.text)\n",
    "\n",
    "# Expected output:\n",
    "print('\\nExpected JSON output:\\n', '{\"product_name\": \"UltraCharge\", \"sales_contribution\": \"40%\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960aa67",
   "metadata": {},
   "source": [
    "### 3. Role Prompting\n",
    "\n",
    "Ask the model to adopt a persona to change tone and focus. Compare outputs.\n",
    "\n",
    "Prompt 1 (Market Research Analyst):\n",
    "```\n",
    "You are a market research analyst. Write a concise 100-word insight report based on:\n",
    "\"Our customer feedback shows growing demand for AI-driven automation tools in logistics and warehouse management.\"\n",
    "```\n",
    "\n",
    "Prompt 2 (Journalist): Same input but persona = journalist. Observe differences in tone and priority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role prompting examples\n",
    "input_text = \"Our customer feedback shows growing demand for AI-driven automation tools in logistics and warehouse management.\"\n",
    "prompts = {\n",
    "    'analyst': f\"You are a market research analyst. Write a concise 100-word insight report based on:\\n\\n{input_text}\",\n",
    "    'journalist': f\"You are a journalist writing for a tech business section. Summarize the key insight in ~100 words based on:\\n\\n{input_text}\"\n",
    "}\n",
    "\n",
    "for role, p in prompts.items():\n",
    "    print(f\"--- Prompt ({role}) ---\\n\", p, \"\\n\")\n",
    "\n",
    "# Replace with real API calls to compare outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87476d",
   "metadata": {},
   "source": [
    "## Phase 2 — Learn (45 min)\n",
    "\n",
    "### 4. Chain-of-Thought Prompting\n",
    "\n",
    "Ask Gemini to show intermediate steps. Use `show_steps` style instructions or explicitly request reasoning steps.\n",
    "\n",
    "Prompt:\n",
    "```\n",
    "A company sells two products: Alpha and Beta.\n",
    "Alpha profit = ₹200 per unit, Beta profit = ₹150 per unit.\n",
    "They sold 180 Alpha and 220 Beta units this month.\n",
    "\n",
    "Calculate total profit step-by-step and give final result in JSON:\n",
    "{\"Total_Profit\": <value_in_rupees>}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795795ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-thought example\n",
    "prompt = (\n",
    "    \"A company sells two products: Alpha and Beta.\\n\"\n",
    "    \"Alpha profit = ₹200 per unit, Beta profit = ₹150 per unit.\\n\"\n",
    "    \"They sold 180 Alpha and 220 Beta units this month.\\n\\n\"\n",
    "    \"Calculate total profit step-by-step and give final result in JSON:\\n\"\n",
    "    '{\"Total_Profit\": \"\"}'\n",
    ")\n",
    "\n",
    "print('Prompt prepared (students should send to Gemini):')\n",
    "print(prompt)\n",
    "\n",
    "# Expected numeric calculation (computed here for verification):\n",
    "alpha_profit = 200 * 180\n",
    "beta_profit = 150 * 220\n",
    "total_profit = alpha_profit + beta_profit\n",
    "print('\\nExpected JSON output:')\n",
    "print({'Total_Profit': total_profit})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dad1a9",
   "metadata": {},
   "source": [
    "### 5. JSON Extraction from Business Reports\n",
    "\n",
    "Input Text (sample invoice):\n",
    "```\n",
    "Invoice ID: 9871\n",
    "Client: BrightTech Pvt. Ltd.\n",
    "Date: 2025-11-13\n",
    "Items:\n",
    " - AI Server (2 units @ ₹80,000)\n",
    " - Edge Sensor Kit (5 units @ ₹12,000)\n",
    "Payment: Pending\n",
    "```\n",
    "\n",
    "Prompt (strict JSON):\n",
    "```\n",
    "Extract the following data in strict JSON format:\n",
    "{\n",
    " \"Invoice_ID\": \"\",\n",
    " \"Client_Name\": \"\",\n",
    " \"Total_Amount\": \"\",\n",
    " \"Payment_Status\": \"\"\n",
    "}\n",
    "```\n",
    "\n",
    "Students should ensure the model computes totals correctly and returns only valid JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total in Python (ground truth) and present prompt\n",
    "invoice_text = '''Invoice ID: 9871\n",
    "Client: BrightTech Pvt. Ltd.\n",
    "Date: 2025-11-13\n",
    "Items:\n",
    " - AI Server (2 units @ ₹80,000)\n",
    " - Edge Sensor Kit (5 units @ ₹12,000)\n",
    "Payment: Pending\n",
    "'''\n",
    "\n",
    "# Compute totals programmatically (instructor verification)\n",
    "ai_server_total = 2 * 80000\n",
    "edge_sensor_total = 5 * 12000\n",
    "computed_total = ai_server_total + edge_sensor_total\n",
    "\n",
    "print('Computed total (INR):', computed_total)\n",
    "\n",
    "prompt = f\"Extract the following data in strict JSON format:\\n{{\\n 'Invoice_ID': '',\\n 'Client_Name': '',\\n 'Total_Amount': '',\\n 'Payment_Status': ''\\n}}\\n\\nSource:\\n{invoice_text}\"\n",
    "print('\\nPrepared prompt for Gemini:\\n')\n",
    "print(prompt)\n",
    "\n",
    "# Expected JSON sample:\n",
    "expected_json = {\n",
    "    \"Invoice_ID\": \"9871\",\n",
    "    \"Client_Name\": \"BrightTech Pvt. Ltd.\",\n",
    "    \"Total_Amount\": f\"₹{computed_total}\",\n",
    "    \"Payment_Status\": \"Pending\"\n",
    "}\n",
    "print('\\nExpected JSON output for verification:\\n')\n",
    "print(expected_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4947e7",
   "metadata": {},
   "source": [
    "### 6. Instruction + Few-shot Prompting for Multi-Entity Extraction\n",
    "\n",
    "Example:\n",
    "```\n",
    "Review: \"The delivery was quick, but packaging was poor.\"\n",
    "Output: {\"Delivery\": \"positive\", \"Packaging\": \"negative\"}\n",
    "```\n",
    "\n",
    "Now try:\n",
    "```\n",
    "\"Excellent product quality, but after-sales support was disappointing.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0329a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the few-shot prompt\n",
    "fewshot = '''Extract customer feedback details from each review and format in JSON.\n",
    "\n",
    "Example:\n",
    "Review: \"The delivery was quick, but packaging was poor.\"\n",
    "Output: {\"Delivery\": \"positive\", \"Packaging\": \"negative\"}\n",
    "\n",
    "Now extract from:\n",
    "\"Excellent product quality, but after-sales support was disappointing.\"'''\n",
    "\n",
    "print(fewshot)\n",
    "\n",
    "# Expected output:\n",
    "print('\\nExpected JSON:\\n', '{\"Product_Quality\": \"positive\", \"After_Sales_Support\": \"negative\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fa505",
   "metadata": {},
   "source": [
    "## Phase 3 — Consolidate (45 min)\n",
    "\n",
    "### 7. Multi-modal Prompting (Text + Image)\n",
    "\n",
    "Provide an image (e.g. sales chart or product lineup) and the accompanying prompt:\n",
    "\n",
    "```\n",
    "Analyze the uploaded image and summarize the insights in two sentences.\n",
    "Then, extract key data points in JSON format:\n",
    "{\n",
    " \"Highest_Selling_Product\": \"\",\n",
    " \"Lowest_Selling_Product\": \"\",\n",
    " \"Observation\": \"\"\n",
    "}\n",
    "```\n",
    "\n",
    "In Colab, students can use the file upload widget and then pass the image bytes to the Gemini multimodal endpoint.\n",
    "\n",
    "### 8. Multi-turn Context Retention Test\n",
    "\n",
    "Turn 1: Provide quarterly sales and ask for summary.\n",
    "Turn 2: Ask for prediction based on the trend and return JSON only.\n",
    "\n",
    "### 9. Self-Consistency Prompting\n",
    "\n",
    "Ask Gemini to reason step-by-step, detect inconsistencies, and return a JSON verdict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder cells for multimodal / multi-turn examples\n",
    "# Uploading images in Colab (example):\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# image_filename = list(uploaded.keys())[0]\n",
    "# with open(image_filename, 'rb') as f:\n",
    "#     image_bytes = f.read()\n",
    "\n",
    "# Example multimodal prompt (instructors will adapt to their SDK):\n",
    "multimodal_prompt = (\n",
    "    \"Analyze the uploaded image and summarize the insights in two sentences. \"\n",
    "    \"Then, extract key data points in JSON format:\\n\"\n",
    "    \"{\\n 'Highest_Selling_Product': '',\\n 'Lowest_Selling_Product': '',\\n 'Observation': ''\\n}\\n\"\n",
    ")\n",
    "print(multimodal_prompt)\n",
    "\n",
    "# Multi-turn example (conceptual):\n",
    "turn1 = 'Q1: 12L, Q2: 15L, Q3: 10L, Q4: 18L. Summarize quarterly trend.'\n",
    "turn2 = 'Based on that trend, predict next year\\'s Q1 assuming a 10% increase from Q4. Return JSON format only: {\"Predicted_Q1\": value}'\n",
    "print('\\nTurn1:', turn1)\n",
    "print('Turn2:', turn2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8e06d",
   "metadata": {},
   "source": [
    "## Reflection & Deliverables\n",
    "\n",
    "Each student should submit:\n",
    "\n",
    "1. `Prompt_Engineering_Lab.ipynb` with outputs for all exercises.\n",
    "2. A 200-word reflective note: 'What I learned about prompt design.'\n",
    "\n",
    "Optional advanced challenge: Prompt compression (<40 words) that extracts company name, product line, and total sales.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271b42",
   "metadata": {},
   "source": [
    "## Instructor notes — Integrating with Gemini API\n",
    "\n",
    "- Replace placeholder pseudo-calls with your institution's Gemini SDK or API client code.\n",
    "- When requiring chain-of-thought, some SDKs require `reasoning: 'detailed'` or to append explicit instructions like \"Think step-by-step:\".\n",
    "- For strict JSON outputs, add post-processing/validation in Python to ensure returned text is valid JSON (e.g. `json.loads(response)` after small cleaning).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
